{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djGTEXK3AJ59",
        "outputId": "743dde1a-13f1-4cb1-f389-2384a7c9a019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting netCDF4\n",
            "  Downloading netcdf4-1.7.3-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting cftime (from netCDF4)\n",
            "  Downloading cftime-1.6.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netCDF4) (2025.10.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from netCDF4) (2.0.2)\n",
            "Downloading netcdf4-1.7.3-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime, netCDF4\n",
            "Successfully installed cftime-1.6.5 netCDF4-1.7.3\n"
          ]
        }
      ],
      "source": [
        "!pip install netCDF4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import netCDF4\n",
        "\n",
        "file_path = \"/content/20250808_prof.nc\"\n",
        "\n",
        "ds = xr.open_dataset(file_path)\n",
        "print(ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buWTndY-A8Td",
        "outputId": "237f9861-b979-4b4d-bfcd-84dc035442a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<xarray.Dataset> Size: 9MB\n",
            "Dimensions:                       (N_PROF: 70, N_PARAM: 3, N_LEVELS: 1485,\n",
            "                                   N_CALIB: 2, N_HISTORY: 0)\n",
            "Dimensions without coordinates: N_PROF, N_PARAM, N_LEVELS, N_CALIB, N_HISTORY\n",
            "Data variables: (12/64)\n",
            "    DATA_TYPE                     object 8B ...\n",
            "    FORMAT_VERSION                object 8B ...\n",
            "    HANDBOOK_VERSION              object 8B ...\n",
            "    REFERENCE_DATE_TIME           object 8B ...\n",
            "    DATE_CREATION                 object 8B ...\n",
            "    DATE_UPDATE                   object 8B ...\n",
            "    ...                            ...\n",
            "    HISTORY_ACTION                (N_HISTORY, N_PROF) object 0B ...\n",
            "    HISTORY_PARAMETER             (N_HISTORY, N_PROF) object 0B ...\n",
            "    HISTORY_START_PRES            (N_HISTORY, N_PROF) float32 0B ...\n",
            "    HISTORY_STOP_PRES             (N_HISTORY, N_PROF) float32 0B ...\n",
            "    HISTORY_PREVIOUS_VALUE        (N_HISTORY, N_PROF) float32 0B ...\n",
            "    HISTORY_QCTEST                (N_HISTORY, N_PROF) object 0B ...\n",
            "Attributes:\n",
            "    title:                Argo float vertical profile\n",
            "    institution:          FR GDAC\n",
            "    source:               Argo float\n",
            "    history:              2025-10-16T04:00:29Z creation\n",
            "    references:           http://www.argodatamgt.org/Documentation\n",
            "    user_manual_version:  3.1\n",
            "    Conventions:          Argo-3.1 CF-1.6\n",
            "    featureType:          trajectoryProfile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import pandas as pd\n",
        "\n",
        "# Extract variables\n",
        "temp = ds[\"TEMP\"].values\n",
        "pres = ds[\"PRES\"].values\n",
        "sal  = ds[\"PSAL\"].values\n",
        "lat  = ds[\"LATITUDE\"].values\n",
        "lon  = ds[\"LONGITUDE\"].values\n",
        "time = ds[\"JULD\"].values\n",
        "\n",
        "# Flatten the data to align profiles with levels\n",
        "nprof, nlevels = temp.shape\n",
        "df = pd.DataFrame({\n",
        "    \"Profile\": [i for i in range(nprof) for _ in range(nlevels)],\n",
        "    \"Latitude\": [lat[i] for i in range(nprof) for _ in range(nlevels)],\n",
        "    \"Longitude\": [lon[i] for i in range(nprof) for _ in range(nlevels)],\n",
        "    \"Time\": [time[i] for i in range(nprof) for _ in range(nlevels)],\n",
        "    \"Pressure\": pres.flatten(),\n",
        "    \"Temperature\": temp.flatten(),\n",
        "    \"Salinity\": sal.flatten()\n",
        "})\n",
        "\n",
        "df.head(50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U4iCZX1OBMqI",
        "outputId": "b616895e-44c6-44be-c83d-2c3977c90578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Profile   Latitude  Longitude                Time   Pressure  Temperature  \\\n",
              "0         0 -54.880965  88.561498 2025-08-08 23:58:30   3.900000        1.913   \n",
              "1         0 -54.880965  88.561498 2025-08-08 23:58:30   5.000000        1.911   \n",
              "2         0 -54.880965  88.561498 2025-08-08 23:58:30   6.200000        1.919   \n",
              "3         0 -54.880965  88.561498 2025-08-08 23:58:30   7.100000        1.920   \n",
              "4         0 -54.880965  88.561498 2025-08-08 23:58:30   8.000000        1.921   \n",
              "5         0 -54.880965  88.561498 2025-08-08 23:58:30   8.800000        1.920   \n",
              "6         0 -54.880965  88.561498 2025-08-08 23:58:30   9.700000        1.921   \n",
              "7         0 -54.880965  88.561498 2025-08-08 23:58:30  10.800000        1.920   \n",
              "8         0 -54.880965  88.561498 2025-08-08 23:58:30  11.900000        1.921   \n",
              "9         0 -54.880965  88.561498 2025-08-08 23:58:30  12.700000        1.920   \n",
              "10        0 -54.880965  88.561498 2025-08-08 23:58:30  13.900000        1.920   \n",
              "11        0 -54.880965  88.561498 2025-08-08 23:58:30  15.200000        1.921   \n",
              "12        0 -54.880965  88.561498 2025-08-08 23:58:30  16.200001        1.921   \n",
              "13        0 -54.880965  88.561498 2025-08-08 23:58:30  17.200001        1.921   \n",
              "14        0 -54.880965  88.561498 2025-08-08 23:58:30  18.200001        1.921   \n",
              "15        0 -54.880965  88.561498 2025-08-08 23:58:30  19.299999        1.921   \n",
              "16        0 -54.880965  88.561498 2025-08-08 23:58:30  20.299999        1.919   \n",
              "17        0 -54.880965  88.561498 2025-08-08 23:58:30  21.400000        1.920   \n",
              "18        0 -54.880965  88.561498 2025-08-08 23:58:30  22.600000        1.919   \n",
              "19        0 -54.880965  88.561498 2025-08-08 23:58:30  23.700001        1.919   \n",
              "20        0 -54.880965  88.561498 2025-08-08 23:58:30  24.900000        1.919   \n",
              "21        0 -54.880965  88.561498 2025-08-08 23:58:30  25.900000        1.920   \n",
              "22        0 -54.880965  88.561498 2025-08-08 23:58:30  26.900000        1.920   \n",
              "23        0 -54.880965  88.561498 2025-08-08 23:58:30  27.900000        1.920   \n",
              "24        0 -54.880965  88.561498 2025-08-08 23:58:30  28.799999        1.917   \n",
              "25        0 -54.880965  88.561498 2025-08-08 23:58:30  30.000000        1.917   \n",
              "26        0 -54.880965  88.561498 2025-08-08 23:58:30  31.200001        1.917   \n",
              "27        0 -54.880965  88.561498 2025-08-08 23:58:30  32.099998        1.919   \n",
              "28        0 -54.880965  88.561498 2025-08-08 23:58:30  32.900002        1.918   \n",
              "29        0 -54.880965  88.561498 2025-08-08 23:58:30  33.799999        1.917   \n",
              "30        0 -54.880965  88.561498 2025-08-08 23:58:30  34.700001        1.918   \n",
              "31        0 -54.880965  88.561498 2025-08-08 23:58:30  35.599998        1.918   \n",
              "32        0 -54.880965  88.561498 2025-08-08 23:58:30  36.900002        1.919   \n",
              "33        0 -54.880965  88.561498 2025-08-08 23:58:30  38.099998        1.919   \n",
              "34        0 -54.880965  88.561498 2025-08-08 23:58:30  39.000000        1.918   \n",
              "35        0 -54.880965  88.561498 2025-08-08 23:58:30  39.799999        1.918   \n",
              "36        0 -54.880965  88.561498 2025-08-08 23:58:30  40.700001        1.918   \n",
              "37        0 -54.880965  88.561498 2025-08-08 23:58:30  41.799999        1.917   \n",
              "38        0 -54.880965  88.561498 2025-08-08 23:58:30  43.099998        1.918   \n",
              "39        0 -54.880965  88.561498 2025-08-08 23:58:30  43.799999        1.917   \n",
              "40        0 -54.880965  88.561498 2025-08-08 23:58:30  44.799999        1.917   \n",
              "41        0 -54.880965  88.561498 2025-08-08 23:58:30  45.799999        1.917   \n",
              "42        0 -54.880965  88.561498 2025-08-08 23:58:30  46.799999        1.918   \n",
              "43        0 -54.880965  88.561498 2025-08-08 23:58:30  48.000000        1.918   \n",
              "44        0 -54.880965  88.561498 2025-08-08 23:58:30  48.900002        1.920   \n",
              "45        0 -54.880965  88.561498 2025-08-08 23:58:30  49.799999        1.921   \n",
              "46        0 -54.880965  88.561498 2025-08-08 23:58:30  51.000000        1.920   \n",
              "47        0 -54.880965  88.561498 2025-08-08 23:58:30  52.299999        1.921   \n",
              "48        0 -54.880965  88.561498 2025-08-08 23:58:30  53.099998        1.922   \n",
              "49        0 -54.880965  88.561498 2025-08-08 23:58:30  53.900002        1.922   \n",
              "\n",
              "     Salinity  \n",
              "0   29.812000  \n",
              "1   29.815001  \n",
              "2   29.813000  \n",
              "3   29.815001  \n",
              "4   29.815001  \n",
              "5   29.815001  \n",
              "6   29.815001  \n",
              "7   29.813999  \n",
              "8   29.813999  \n",
              "9   29.815001  \n",
              "10  29.813999  \n",
              "11  29.815001  \n",
              "12  29.813999  \n",
              "13  29.815001  \n",
              "14  29.815001  \n",
              "15  29.813999  \n",
              "16  29.815001  \n",
              "17  29.813999  \n",
              "18  29.815001  \n",
              "19  29.813999  \n",
              "20  29.815001  \n",
              "21  29.813999  \n",
              "22  29.815001  \n",
              "23  29.813999  \n",
              "24  29.815001  \n",
              "25  29.813999  \n",
              "26  29.815001  \n",
              "27  29.813999  \n",
              "28  29.813999  \n",
              "29  29.813999  \n",
              "30  29.813999  \n",
              "31  29.815001  \n",
              "32  29.813999  \n",
              "33  29.813999  \n",
              "34  29.813999  \n",
              "35  29.813999  \n",
              "36  29.813999  \n",
              "37  29.813999  \n",
              "38  29.813999  \n",
              "39  29.813999  \n",
              "40  29.813999  \n",
              "41  29.813999  \n",
              "42  29.813999  \n",
              "43  29.815001  \n",
              "44  29.813000  \n",
              "45  29.813999  \n",
              "46  29.813999  \n",
              "47  29.813999  \n",
              "48  29.813999  \n",
              "49  29.813000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c06f2bd-3cf7-45cb-bb13-0d195d3b124e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Profile</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Time</th>\n",
              "      <th>Pressure</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Salinity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>1.913</td>\n",
              "      <td>29.812000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.911</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>1.919</td>\n",
              "      <td>29.813000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>7.100000</td>\n",
              "      <td>1.920</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.921</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>1.920</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>1.921</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>1.920</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>11.900000</td>\n",
              "      <td>1.921</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>12.700000</td>\n",
              "      <td>1.920</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>13.900000</td>\n",
              "      <td>1.920</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>15.200000</td>\n",
              "      <td>1.921</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>16.200001</td>\n",
              "      <td>1.921</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>17.200001</td>\n",
              "      <td>1.921</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>18.200001</td>\n",
              "      <td>1.921</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>19.299999</td>\n",
              "      <td>1.921</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>20.299999</td>\n",
              "      <td>1.919</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>21.400000</td>\n",
              "      <td>1.920</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>22.600000</td>\n",
              "      <td>1.919</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>23.700001</td>\n",
              "      <td>1.919</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>24.900000</td>\n",
              "      <td>1.919</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>25.900000</td>\n",
              "      <td>1.920</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>26.900000</td>\n",
              "      <td>1.920</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>27.900000</td>\n",
              "      <td>1.920</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>28.799999</td>\n",
              "      <td>1.917</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.917</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>31.200001</td>\n",
              "      <td>1.917</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>32.099998</td>\n",
              "      <td>1.919</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>32.900002</td>\n",
              "      <td>1.918</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>33.799999</td>\n",
              "      <td>1.917</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>34.700001</td>\n",
              "      <td>1.918</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>35.599998</td>\n",
              "      <td>1.918</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>36.900002</td>\n",
              "      <td>1.919</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>38.099998</td>\n",
              "      <td>1.919</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>1.918</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>39.799999</td>\n",
              "      <td>1.918</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>40.700001</td>\n",
              "      <td>1.918</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>41.799999</td>\n",
              "      <td>1.917</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>43.099998</td>\n",
              "      <td>1.918</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>43.799999</td>\n",
              "      <td>1.917</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>44.799999</td>\n",
              "      <td>1.917</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>45.799999</td>\n",
              "      <td>1.917</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>46.799999</td>\n",
              "      <td>1.918</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>1.918</td>\n",
              "      <td>29.815001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>48.900002</td>\n",
              "      <td>1.920</td>\n",
              "      <td>29.813000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>49.799999</td>\n",
              "      <td>1.921</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>1.920</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>52.299999</td>\n",
              "      <td>1.921</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>53.099998</td>\n",
              "      <td>1.922</td>\n",
              "      <td>29.813999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0</td>\n",
              "      <td>-54.880965</td>\n",
              "      <td>88.561498</td>\n",
              "      <td>2025-08-08 23:58:30</td>\n",
              "      <td>53.900002</td>\n",
              "      <td>1.922</td>\n",
              "      <td>29.813000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c06f2bd-3cf7-45cb-bb13-0d195d3b124e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c06f2bd-3cf7-45cb-bb13-0d195d3b124e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c06f2bd-3cf7-45cb-bb13-0d195d3b124e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-966ec13e-2903-43ca-9dcf-1b40e29bd53c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-966ec13e-2903-43ca-9dcf-1b40e29bd53c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-966ec13e-2903-43ca-9dcf-1b40e29bd53c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "# Base URL\n",
        "BASE_URL = \"https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/\"\n",
        "LOCAL_DIR = \"/content/data/indian_ocean/2025/01/\"\n",
        "\n",
        "# Ensure local directory exists\n",
        "os.makedirs(LOCAL_DIR, exist_ok=True)\n",
        "\n",
        "def get_nc_files(url):\n",
        "    \"\"\"Scrape the directory listing to get .nc file URLs\"\"\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    links = [a['href'] for a in soup.find_all('a', href=True) if a['href'].endswith('.nc')]\n",
        "    return [urljoin(url, link) for link in links]\n",
        "\n",
        "def download_file(file_url, local_path):\n",
        "    \"\"\"Download a file if not already present\"\"\"\n",
        "    if os.path.exists(local_path):\n",
        "        print(f\"✅ Skipping (exists): {local_path}\")\n",
        "        return\n",
        "    print(f\"⬇️ Downloading: {file_url}\")\n",
        "    r = requests.get(file_url, stream=True)\n",
        "    with open(local_path, \"wb\") as f:\n",
        "        for chunk in r.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "    print(f\"✅ Saved: {local_path}\")\n",
        "\n",
        "def main():\n",
        "    file_urls = get_nc_files(BASE_URL)\n",
        "    for file_url in file_urls:\n",
        "        filename = os.path.basename(file_url)\n",
        "        local_path = os.path.join(LOCAL_DIR, filename)\n",
        "        download_file(file_url, local_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "E4IXfg7bBXjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed9ea22-d899-4aa4-fa07-76f2686669a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250101_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250101_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250102_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250102_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250103_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250103_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250104_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250104_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250105_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250105_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250106_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250106_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250107_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250107_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250108_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250108_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250109_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250109_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250110_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250110_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250111_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250111_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250112_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250112_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250113_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250113_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250114_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250114_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250115_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250115_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250116_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250116_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250117_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250117_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250118_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250118_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250119_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250119_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250120_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250120_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250121_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250121_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250122_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250122_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250123_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250123_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250124_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250124_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250125_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250125_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250126_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250126_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250127_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250127_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250128_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250128_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250129_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250129_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250130_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250130_prof.nc\n",
            "⬇️ Downloading: https://data-argo.ifremer.fr/geo/indian_ocean/2025/01/20250131_prof.nc\n",
            "✅ Saved: /content/data/indian_ocean/2025/01/20250131_prof.nc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import netCDF4\n",
        "\n",
        "file_path = \"/content/data/indian_ocean/2025/01/20250101_prof.nc\"\n",
        "\n",
        "ds = xr.open_dataset(file_path)\n",
        "print(ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apRxMtM7jruF",
        "outputId": "ddbc2d1a-79d6-431f-f358-993d0e3ff770"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<xarray.Dataset> Size: 9MB\n",
            "Dimensions:                       (N_PROF: 77, N_PARAM: 3, N_LEVELS: 1334,\n",
            "                                   N_CALIB: 3, N_HISTORY: 0)\n",
            "Dimensions without coordinates: N_PROF, N_PARAM, N_LEVELS, N_CALIB, N_HISTORY\n",
            "Data variables: (12/64)\n",
            "    DATA_TYPE                     object 8B ...\n",
            "    FORMAT_VERSION                object 8B ...\n",
            "    HANDBOOK_VERSION              object 8B ...\n",
            "    REFERENCE_DATE_TIME           object 8B ...\n",
            "    DATE_CREATION                 object 8B ...\n",
            "    DATE_UPDATE                   object 8B ...\n",
            "    ...                            ...\n",
            "    HISTORY_ACTION                (N_HISTORY, N_PROF) object 0B ...\n",
            "    HISTORY_PARAMETER             (N_HISTORY, N_PROF) object 0B ...\n",
            "    HISTORY_START_PRES            (N_HISTORY, N_PROF) float32 0B ...\n",
            "    HISTORY_STOP_PRES             (N_HISTORY, N_PROF) float32 0B ...\n",
            "    HISTORY_PREVIOUS_VALUE        (N_HISTORY, N_PROF) float32 0B ...\n",
            "    HISTORY_QCTEST                (N_HISTORY, N_PROF) object 0B ...\n",
            "Attributes:\n",
            "    title:                Argo float vertical profile\n",
            "    institution:          FR GDAC\n",
            "    source:               Argo float\n",
            "    history:              2025-11-01T17:55:21Z creation\n",
            "    references:           http://www.argodatamgt.org/Documentation\n",
            "    user_manual_version:  3.1\n",
            "    Conventions:          Argo-3.1 CF-1.6\n",
            "    featureType:          trajectoryProfile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ij1TaVu5m3KL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a93ddfb6"
      },
      "source": [
        "# Task\n",
        "Summarize the extracted `N_PROF` and `N_LEVELS` information for all NetCDF files in the directory `/content/data/indian_ocean/2025/01/`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1901108"
      },
      "source": [
        "## List NetCDF Files\n",
        "\n",
        "### Subtask:\n",
        "Identify and list all `.nc` files present in the directory `/content/data/indian_ocean/2025/01/`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df5f6989"
      },
      "source": [
        "**Reasoning**:\n",
        "The first instruction is to import the `os` module, which is necessary for interacting with the file system to list files in a directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81bf8e15",
        "outputId": "93fa0631-ce06-4eb0-a572-542f9ada83a6"
      },
      "source": [
        "import os\n",
        "\n",
        "print(\"os module imported.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "os module imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b0809c4"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `os` module is imported, I will define the directory path, list all items in it using `os.listdir()`, and filter the list to include only files ending with `.nc`, storing them in a variable as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c4b8da4",
        "outputId": "5c02c8eb-e220-4094-974a-0dd75bc09e3b"
      },
      "source": [
        "directory_path = \"/content/data/indian_ocean/2025/01/\"\n",
        "all_files = os.listdir(directory_path)\n",
        "nc_files = [file for file in all_files if file.endswith('.nc')]\n",
        "\n",
        "print(f\"Found {len(nc_files)} NetCDF files:\")\n",
        "for file in nc_files:\n",
        "    print(file)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31 NetCDF files:\n",
            "20250118_prof.nc\n",
            "20250125_prof.nc\n",
            "20250126_prof.nc\n",
            "20250101_prof.nc\n",
            "20250130_prof.nc\n",
            "20250121_prof.nc\n",
            "20250105_prof.nc\n",
            "20250115_prof.nc\n",
            "20250123_prof.nc\n",
            "20250122_prof.nc\n",
            "20250116_prof.nc\n",
            "20250102_prof.nc\n",
            "20250103_prof.nc\n",
            "20250120_prof.nc\n",
            "20250113_prof.nc\n",
            "20250108_prof.nc\n",
            "20250104_prof.nc\n",
            "20250129_prof.nc\n",
            "20250117_prof.nc\n",
            "20250131_prof.nc\n",
            "20250109_prof.nc\n",
            "20250112_prof.nc\n",
            "20250127_prof.nc\n",
            "20250107_prof.nc\n",
            "20250111_prof.nc\n",
            "20250106_prof.nc\n",
            "20250110_prof.nc\n",
            "20250114_prof.nc\n",
            "20250128_prof.nc\n",
            "20250119_prof.nc\n",
            "20250124_prof.nc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84005090"
      },
      "source": [
        "## Extract Dimensions from Each File\n",
        "\n",
        "### Subtask:\n",
        "For each .nc file, open it using xarray, extract the values for N_PROF and N_LEVELS dimensions, and store this information.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "483cc772"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to import the `xarray` library to open and process the NetCDF files. This is the first step as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2082adb8",
        "outputId": "a518bd52-d213-473e-bd9f-4f5193aa9fe5"
      },
      "source": [
        "import xarray as xr\n",
        "\n",
        "print(\"xarray imported as xr.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xarray imported as xr.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f03641a8"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that `xarray` is imported, I will create an empty list `dimensions_data`, iterate through the `nc_files`, construct the full path for each file, open it with `xr.open_dataset()`, extract `N_PROF` and `N_LEVELS` dimensions using `.get()` to handle missing dimensions gracefully, append the information to `dimensions_data`, and then close each dataset to manage resources, as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af36e03d",
        "outputId": "9052b83f-b8df-4526-b601-66fb89d910f5"
      },
      "source": [
        "dimensions_data = []\n",
        "\n",
        "for filename in nc_files:\n",
        "    full_path = os.path.join(directory_path, filename)\n",
        "    with xr.open_dataset(full_path) as ds:\n",
        "        n_prof_val = ds.dims.get('N_PROF', None)\n",
        "        n_levels_val = ds.dims.get('N_LEVELS', None)\n",
        "        dimensions_data.append({\n",
        "            'filename': filename,\n",
        "            'N_PROF': n_prof_val,\n",
        "            'N_LEVELS': n_levels_val\n",
        "        })\n",
        "\n",
        "print(f\"Extracted dimensions for {len(dimensions_data)} files.\")\n",
        "# Optionally, display the first few entries\n",
        "# print(dimensions_data[:5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted dimensions for 31 files.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n",
            "/tmp/ipython-input-324121108.py:6: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_prof_val = ds.dims.get('N_PROF', None)\n",
            "<frozen _collections_abc>:807: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "/tmp/ipython-input-324121108.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
            "  n_levels_val = ds.dims.get('N_LEVELS', None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8bbd3b6"
      },
      "source": [
        "**Reasoning**:\n",
        "To address the `FutureWarning` about `Dataset.dims` being deprecated for dimension lengths, I will update the code to use `Dataset.sizes` which is the recommended way to access dimension lengths. This will remove the warnings while keeping the functionality the same.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1b46a40",
        "outputId": "1654a859-4a31-4d35-a6cc-4b282e963f4c"
      },
      "source": [
        "dimensions_data = []\n",
        "\n",
        "for filename in nc_files:\n",
        "    full_path = os.path.join(directory_path, filename)\n",
        "    with xr.open_dataset(full_path) as ds:\n",
        "        n_prof_val = ds.sizes.get('N_PROF', None)\n",
        "        n_levels_val = ds.sizes.get('N_LEVELS', None)\n",
        "        dimensions_data.append({\n",
        "            'filename': filename,\n",
        "            'N_PROF': n_prof_val,\n",
        "            'N_LEVELS': n_levels_val\n",
        "        })\n",
        "\n",
        "print(f\"Extracted dimensions for {len(dimensions_data)} files.\")\n",
        "# Optionally, display the first few entries\n",
        "# print(dimensions_data[:5])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted dimensions for 31 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8220c08a"
      },
      "source": [
        "## Display Dimensions\n",
        "\n",
        "### Subtask:\n",
        "Print the filename along with its corresponding N_PROF and N_LEVELS values for each processed file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "510dd86b"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to iterate through the `dimensions_data` list and print the filename, N_PROF, and N_LEVELS for each entry as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4438bc9",
        "outputId": "694082aa-26b1-4326-c1c8-1d18de4d1040"
      },
      "source": [
        "print(\"Summary of N_PROF and N_LEVELS for each file:\")\n",
        "for entry in dimensions_data:\n",
        "    print(f\"File: {entry['filename']}, N_PROF: {entry['N_PROF']}, N_LEVELS: {entry['N_LEVELS']}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of N_PROF and N_LEVELS for each file:\n",
            "File: 20250118_prof.nc, N_PROF: 68, N_LEVELS: 1165\n",
            "File: 20250125_prof.nc, N_PROF: 89, N_LEVELS: 1218\n",
            "File: 20250126_prof.nc, N_PROF: 91, N_LEVELS: 1411\n",
            "File: 20250101_prof.nc, N_PROF: 77, N_LEVELS: 1334\n",
            "File: 20250130_prof.nc, N_PROF: 69, N_LEVELS: 1361\n",
            "File: 20250121_prof.nc, N_PROF: 81, N_LEVELS: 1294\n",
            "File: 20250105_prof.nc, N_PROF: 87, N_LEVELS: 1021\n",
            "File: 20250115_prof.nc, N_PROF: 96, N_LEVELS: 1193\n",
            "File: 20250123_prof.nc, N_PROF: 98, N_LEVELS: 1394\n",
            "File: 20250122_prof.nc, N_PROF: 72, N_LEVELS: 1544\n",
            "File: 20250116_prof.nc, N_PROF: 91, N_LEVELS: 1200\n",
            "File: 20250102_prof.nc, N_PROF: 86, N_LEVELS: 1323\n",
            "File: 20250103_prof.nc, N_PROF: 88, N_LEVELS: 1521\n",
            "File: 20250120_prof.nc, N_PROF: 74, N_LEVELS: 1409\n",
            "File: 20250113_prof.nc, N_PROF: 91, N_LEVELS: 1486\n",
            "File: 20250108_prof.nc, N_PROF: 76, N_LEVELS: 2000\n",
            "File: 20250104_prof.nc, N_PROF: 63, N_LEVELS: 1117\n",
            "File: 20250129_prof.nc, N_PROF: 79, N_LEVELS: 1354\n",
            "File: 20250117_prof.nc, N_PROF: 75, N_LEVELS: 2001\n",
            "File: 20250131_prof.nc, N_PROF: 81, N_LEVELS: 1547\n",
            "File: 20250109_prof.nc, N_PROF: 72, N_LEVELS: 1323\n",
            "File: 20250112_prof.nc, N_PROF: 72, N_LEVELS: 1307\n",
            "File: 20250127_prof.nc, N_PROF: 76, N_LEVELS: 2000\n",
            "File: 20250107_prof.nc, N_PROF: 72, N_LEVELS: 1314\n",
            "File: 20250111_prof.nc, N_PROF: 89, N_LEVELS: 1298\n",
            "File: 20250106_prof.nc, N_PROF: 86, N_LEVELS: 1204\n",
            "File: 20250110_prof.nc, N_PROF: 71, N_LEVELS: 1412\n",
            "File: 20250114_prof.nc, N_PROF: 59, N_LEVELS: 1389\n",
            "File: 20250128_prof.nc, N_PROF: 74, N_LEVELS: 1403\n",
            "File: 20250119_prof.nc, N_PROF: 73, N_LEVELS: 1397\n",
            "File: 20250124_prof.nc, N_PROF: 58, N_LEVELS: 1012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc9ebd12"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the extracted N_PROF and N_LEVELS information for all files in the directory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9191e6a9"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   A total of 31 NetCDF files were identified in the directory `/content/data/indian_ocean/2025/01/`.\n",
        "*   For each of these files, the `N_PROF` and `N_LEVELS` dimension values were successfully extracted using `xarray`.\n",
        "*   The extraction process was refined to use `ds.sizes.get()` for retrieving dimension lengths, which addressed `FutureWarning` messages related to `Dataset.dims` and ensures compatibility with future `xarray` versions.\n",
        "*   The `N_PROF` and `N_LEVELS` values varied across files; for example:\n",
        "    *   `20250118_prof.nc` had `N_PROF`: 68 and `N_LEVELS`: 1165.\n",
        "    *   `20250125_prof.nc` had `N_PROF`: 89 and `N_LEVELS`: 1218.\n",
        "    *   `20250101_prof.nc` had `N_PROF`: 77 and `N_LEVELS`: 1334.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   This summary provides a foundational understanding of the profile and level counts within each NetCDF file, which is crucial for subsequent data processing and analysis, such as ensuring consistent data structures or identifying outliers.\n",
        "*   Further analysis could involve calculating descriptive statistics (e.g., minimum, maximum, average, standard deviation) for `N_PROF` and `N_LEVELS` across all files to understand the overall characteristics and variability of the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_n_prof = sum([entry['N_PROF'] for entry in dimensions_data])\n",
        "total_n_levels = sum([entry['N_LEVELS'] for entry in dimensions_data])\n",
        "num_files = len(dimensions_data)\n",
        "\n",
        "average_n_prof = total_n_prof / num_files\n",
        "average_n_levels = total_n_levels / num_files\n",
        "\n",
        "print(f\"Average N_PROF across all files: {average_n_prof:.2f}\")\n",
        "print(f\"Average N_LEVELS across all files: {average_n_levels:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USPY4sabp84H",
        "outputId": "27ed6687-8302-4034-cdbd-d829c00b9f6c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average N_PROF across all files: 78.52\n",
            "Average N_LEVELS across all files: 1385.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def extract_profiles(nc_file):\n",
        "    ds = xr.open_dataset(nc_file)\n",
        "\n",
        "    # --- Identify dimensions safely ---\n",
        "    n_prof = ds.sizes.get(\"N_PROF\", 0)\n",
        "    n_levels = ds.sizes.get(\"N_LEVELS\", 0)\n",
        "    if n_prof == 0 or n_levels == 0:\n",
        "        print(f\"⚠️ Skipping file (no valid dimensions): {nc_file}\")\n",
        "        ds.close()\n",
        "        return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "    # --- Extract core variables ---\n",
        "    pres = ds[\"PRES\"].values if \"PRES\" in ds.variables else np.full((n_prof, n_levels), np.nan)\n",
        "    temp = ds[\"TEMP\"].values if \"TEMP\" in ds.variables else np.full((n_prof, n_levels), np.nan)\n",
        "    psal = ds[\"PSAL\"].values if \"PSAL\" in ds.variables else np.full((n_prof, n_levels), np.nan)\n",
        "    lat = ds[\"LATITUDE\"].values if \"LATITUDE\" in ds.variables else np.full(n_prof, np.nan)\n",
        "    lon = ds[\"LONGITUDE\"].values if \"LONGITUDE\" in ds.variables else np.full(n_prof, np.nan)\n",
        "\n",
        "    # --- Build measurements table (normalized) ---\n",
        "    measurements_records = []\n",
        "    for i in range(n_prof):\n",
        "        for j in range(n_levels):\n",
        "            # Skip empty measurements\n",
        "            if np.isnan(pres[i, j]) or np.isnan(temp[i, j]) or np.isnan(psal[i, j]):\n",
        "                continue\n",
        "            measurements_records.append({\n",
        "                \"profile_id\": i,  # local profile index within file\n",
        "                \"level\": j,\n",
        "                \"pressure\": float(pres[i, j]),\n",
        "                \"temperature\": float(temp[i, j]),\n",
        "                \"salinity\": float(psal[i, j])\n",
        "            })\n",
        "\n",
        "    measurements_df = pd.DataFrame(measurements_records)\n",
        "\n",
        "    # --- Build profiles table (metadata) ---\n",
        "    profiles_records = []\n",
        "    for i in range(n_prof):\n",
        "        # Try to get datetime safely\n",
        "        try:\n",
        "            datetime_val = pd.to_datetime(ds[\"JULD\"][i].values)\n",
        "        except Exception:\n",
        "            datetime_val = None\n",
        "\n",
        "        # Handle float_id safely (can be array of chars)\n",
        "        if \"PLATFORM_NUMBER\" in ds.variables:\n",
        "            float_id = str(ds[\"PLATFORM_NUMBER\"][i].values)\n",
        "            float_id = float_id.strip(\"[]\").replace(\" \", \"\").replace(\"'\", \"\")\n",
        "        else:\n",
        "            float_id = \"unknown\"\n",
        "\n",
        "        record = {\n",
        "            \"profile_id\": i,\n",
        "            \"float_id\": float_id,\n",
        "            \"cycle_number\": int(ds[\"CYCLE_NUMBER\"][i].values) if \"CYCLE_NUMBER\" in ds.variables else None,\n",
        "            \"datetime\": datetime_val,\n",
        "            \"latitude\": float(lat[i]) if not np.isnan(lat[i]) else None,\n",
        "            \"longitude\": float(lon[i]) if not np.isnan(lon[i]) else None,\n",
        "            \"project_name\": str(ds.attrs.get(\"project_name\", \"ARGO\")),\n",
        "            \"data_mode\": str(ds.attrs.get(\"data_mode\", \"R\")),\n",
        "            \"platform_type\": str(ds.attrs.get(\"platform_type\", \"unknown\")),\n",
        "            \"institution\": str(ds.attrs.get(\"institution\", \"unknown\")),\n",
        "            \"title\": str(ds.attrs.get(\"title\", \"unknown\")),\n",
        "            \"source\": str(ds.attrs.get(\"source\", \"unknown\")),\n",
        "            \"min_pressure\": float(np.nanmin(pres[i])) if np.any(~np.isnan(pres[i])) else None,\n",
        "            \"max_pressure\": float(np.nanmax(pres[i])) if np.any(~np.isnan(pres[i])) else None,\n",
        "            \"measured_parameters\": \", \".join([v for v in ds.data_vars if v not in [\"N_PROF\", \"N_LEVELS\"]])\n",
        "        }\n",
        "        profiles_records.append(record)\n",
        "\n",
        "    profiles_df = pd.DataFrame(profiles_records)\n",
        "\n",
        "    ds.close()\n",
        "\n",
        "    print(f\"✅ Extracted {len(profiles_df)} profiles and {len(measurements_df)} measurements.\")\n",
        "    return profiles_df, measurements_df\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    nc_file = \"/content/data/indian_ocean/2025/01/20250101_prof.nc\"\n",
        "    profiles_df, measurements_df = extract_profiles(nc_file)\n",
        "\n",
        "    print(\"\\n--- Profiles Table ---\")\n",
        "    print(profiles_df.head())\n",
        "\n",
        "    print(\"\\n--- Measurements Table ---\")\n",
        "    print(measurements_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3u2kmP-Fd_7",
        "outputId": "731893de-1133-4433-f999-575302ff707a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extracted 77 profiles and 49620 measurements.\n",
            "\n",
            "--- Profiles Table ---\n",
            "   profile_id  float_id  cycle_number            datetime   latitude  \\\n",
            "0           0  b5906527            94 2025-01-01 23:10:46 -43.513000   \n",
            "1           1  b5905521            96 2025-01-01 22:30:06  -8.248500   \n",
            "2           2  b5906256           168 2025-01-01 22:23:17 -43.034000   \n",
            "3           3  b1902259           164 2025-01-01 22:06:27 -33.786720   \n",
            "4           4  b7900576           146 2025-01-01 21:39:20 -45.424212   \n",
            "\n",
            "   longitude project_name data_mode platform_type institution  \\\n",
            "0   35.46800         ARGO         R       unknown     FR GDAC   \n",
            "1  105.79380         ARGO         R       unknown     FR GDAC   \n",
            "2  134.93100         ARGO         R       unknown     FR GDAC   \n",
            "3   55.46375         ARGO         R       unknown     FR GDAC   \n",
            "4   43.18347         ARGO         R       unknown     FR GDAC   \n",
            "\n",
            "                         title      source  min_pressure  max_pressure  \\\n",
            "0  Argo float vertical profile  Argo float          4.40   1598.229980   \n",
            "1  Argo float vertical profile  Argo float          4.10   2003.699951   \n",
            "2  Argo float vertical profile  Argo float          4.40   1997.939941   \n",
            "3  Argo float vertical profile  Argo float          0.96   2005.239990   \n",
            "4  Argo float vertical profile  Argo float          5.20   1580.900024   \n",
            "\n",
            "                                 measured_parameters  \n",
            "0  DATA_TYPE, FORMAT_VERSION, HANDBOOK_VERSION, R...  \n",
            "1  DATA_TYPE, FORMAT_VERSION, HANDBOOK_VERSION, R...  \n",
            "2  DATA_TYPE, FORMAT_VERSION, HANDBOOK_VERSION, R...  \n",
            "3  DATA_TYPE, FORMAT_VERSION, HANDBOOK_VERSION, R...  \n",
            "4  DATA_TYPE, FORMAT_VERSION, HANDBOOK_VERSION, R...  \n",
            "\n",
            "--- Measurements Table ---\n",
            "   profile_id  level  pressure  temperature   salinity\n",
            "0           0      0       4.4       10.852  34.022999\n",
            "1           0      1       6.0       10.852  34.022999\n",
            "2           0      2       8.0       10.852  34.022999\n",
            "3           0      3      10.0       10.851  34.022999\n",
            "4           0      4      12.0       10.852  34.022999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## profiles_df → Vector DB\n",
        "\n",
        "This DataFrame has all the contextual metadata about each profile:\n",
        "\n",
        "float_id, cycle_number, datetime, latitude, longitude,\n",
        "project_name, data_mode, platform_type, institution, title,\n",
        "source, measured_parameters, min_pressure, max_pressure\n",
        "\n",
        "\n",
        "LLMs can use this to answer questions like:\n",
        "\n",
        "“Which Argo floats were deployed by INCOIS in January 2025?”\n",
        "“Find the float that measured deepest salinity profiles near equator.”\n",
        "\n",
        "These don’t need precise numeric filtering — instead, they’re semantic / contextual.\n",
        "\n",
        "## measurements_df → PostgreSQL\n",
        "\n",
        "Contains the actual depth-wise numeric data:\n",
        "\n",
        "profile_id, level, pressure, temperature, salinity\n",
        "\n",
        "\n",
        "This is what your system queries when the user asks:\n",
        "\n",
        "“What’s the temperature 30 m off the coast of Tamil Nadu?”\n",
        "“Show me salinity at 50 dbar for profile 102.”\n",
        "\n",
        "PostgreSQL can handle these fast and precisely using indexes on pressure, latitude, longitude."
      ],
      "metadata": {
        "id": "cYoHxQ3FGTZi"
      }
    }
  ]
}